language: "en"

pipeline:
##- name: "nlp_spacy"
- name: "tokenizer_whitespace"
- name: "intent_entity_featurizer_regex"
- name: "ner_crf"
##- name: "ner_spacy"
- name: "ner_synonyms"
- name: "TitlecaseNamedEntities.TitlecaseNamedEntities"
- name: intent_featurizer_count_vectors
  analyzer: 'char' 
  min_ngram: 1  
  max_ngram: 3 
- name: intent_classifier_tensorflow_embedding
  # nn architecture
  "hidden_layers_sizes_a": [256, 128]
  "hidden_layers_sizes_b": []
  "batch_size": [64, 256]
  "epochs": 400
  # embedding parameters
  "embed_dim": 20
  "mu_pos": 0.8  # should be 0.0 < ... < 1.0 for 'cosine'
  "mu_neg": -0.4  # should be -1.0 < ... < 1.0 for 'cosine'
  "similarity_type": "cosine"  # string 'cosine' or 'inner'
  "num_neg": 20
  "use_max_sim_neg": true  # flag which loss function to use
  "random_seed": None # set to any int to generate a reproducible training result
  # regularization
  "C2": 0.002
  "C_emb": 0.8
  "droprate": 0.2
  # flag for tokenizing intents
  "intent_tokenization_flag": true
  "intent_split_symbol": "+"
  # visualization of accuracy
  "evaluate_every_num_epochs": 20  # small values may hurt performance
  "evaluate_on_num_examples": 200  # large values   may hurt performance
- name: ner_duckling_http
  url: http://localhost:8000
  dimensions:
  - time
  timezone: "Europe/Berlin"
